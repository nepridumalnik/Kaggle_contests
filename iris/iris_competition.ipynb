{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58b6e048",
   "metadata": {},
   "source": [
    "[Iris dataset competition](https://www.kaggle.com/competitions/iris-dataset-competition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8a3fe75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PATH = \"data\"\n",
    "TRAIN_CSV = os.path.join(PATH, \"iris_train.csv\")\n",
    "TEST_CSV = os.path.join(PATH, \"iris_test.csv\")\n",
    "\n",
    "if not os.path.exists(PATH):\n",
    "    raise FileNotFoundError(f\"{PATH} not found\")\n",
    "\n",
    "if not os.path.exists(TRAIN_CSV):\n",
    "    raise FileNotFoundError(f\"{TRAIN_CSV} not found\")\n",
    "\n",
    "if not os.path.exists(TEST_CSV):\n",
    "    raise FileNotFoundError(f\"{TEST_CSV} not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0867bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def drop_unnamed_columns(df):\n",
    "    df.drop(\n",
    "        df.columns[df.columns.str.contains(\"unnamed\", case=False)], axis=1, inplace=True\n",
    "    )\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "test_df[\"target\"] = np.zeros(test_df.shape[0], dtype=np.int64)\n",
    "\n",
    "\n",
    "drop_unnamed_columns(train_df)\n",
    "drop_unnamed_columns(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1fe1bfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.7               2.9                4.2               1.3   \n",
       "1                7.6               3.0                6.6               2.1   \n",
       "2                5.6               3.0                4.5               1.5   \n",
       "3                5.1               3.5                1.4               0.2   \n",
       "4                7.7               2.8                6.7               2.0   \n",
       "\n",
       "   target  \n",
       "0     1.0  \n",
       "1     2.0  \n",
       "2     1.0  \n",
       "3     0.0  \n",
       "4     2.0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7588ba79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                6.1               2.8                4.7               1.2   \n",
       "1                5.7               3.8                1.7               0.3   \n",
       "2                7.7               2.6                6.9               2.3   \n",
       "3                6.0               2.9                4.5               1.5   \n",
       "4                6.8               2.8                4.8               1.4   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91acd102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "TEST_SIZE = 0.15\n",
    "\n",
    "X = train_df.values.astype(np.float64)\n",
    "Y = train_df[\"target\"].astype(np.int64)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=Y,\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "341ac903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class IrisDS(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        has_labels: bool = True,\n",
    "        mean: torch.Tensor | None = None,\n",
    "        std: torch.Tensor | None = None,\n",
    "        target_col: str = \"target\",\n",
    "    ):\n",
    "        self.has_labels = has_labels\n",
    "\n",
    "        X = df.drop(columns=[target_col], errors=\"ignore\").to_numpy(dtype=np.float32)\n",
    "        self.X = torch.from_numpy(X)\n",
    "\n",
    "        if has_labels:\n",
    "            y = pd.Categorical(df[target_col]).codes.astype(np.int64)\n",
    "            self.Y = torch.from_numpy(y)\n",
    "\n",
    "        if mean is None or std is None:\n",
    "            self.mean = self.X.mean(0, keepdim=True)\n",
    "            self.std = self.X.std(0, unbiased=False, keepdim=True).clamp_min(1e-6)\n",
    "        else:\n",
    "            self.mean = torch.as_tensor(mean, dtype=self.X.dtype).view(1, -1)\n",
    "            self.std = torch.as_tensor(std, dtype=self.X.dtype).view(1, -1)\n",
    "\n",
    "        self.X = (self.X - self.mean) / self.std\n",
    "\n",
    "        if has_labels and len(self.X) != len(self.Y):\n",
    "            raise ValueError(\n",
    "                f\"Length of X ({len(self.X)}) and Y ({len(self.Y)}) must be equal\"\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        if self.has_labels:\n",
    "            y = self.Y[idx]\n",
    "            return x, y\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ef56764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim, nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "class IrisModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, iris_columns=4, species_num=3, lr=1e-3, lr_decay=1e-7, weight_decay=1e-4\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(iris_columns, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(5, 25),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(25, 35),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(35, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(5, species_num),\n",
    "        )\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.lr = lr\n",
    "        self.lr_decay = lr_decay\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def __step(self, batch, stage):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log(f\"{stage}_loss\", loss, prog_bar=True)\n",
    "        self.log(f\"{stage}_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        return self.__step(batch, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        self.__step(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, _):\n",
    "        self.__step(batch, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(\n",
    "            self.parameters(), lr=self.lr, weight_decay=self.weight_decay\n",
    "        )\n",
    "\n",
    "        def handle_lr(step):\n",
    "            new_lr = self.lr - self.lr_decay * step\n",
    "            return max(new_lr, 0.0) / self.lr\n",
    "\n",
    "        scheduler = optim.lr_scheduler.LambdaLR(\n",
    "            optimizer=optimizer,\n",
    "            lr_lambda=handle_lr,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "            },\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3dc75b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\0\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | net     | Sequential       | 1.3 K  | train\n",
      "1 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\0\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 13/13 [00:00<00:00, 262.83it/s, train_loss=0.014, train_acc=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 13/13 [00:00<00:00, 250.15it/s, train_loss=0.014, train_acc=1.000]\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCHS = 100\n",
    "ENABLE_CHECKPOINTING = False\n",
    "LOGGER = False\n",
    "\n",
    "ds = IrisDS(train_df)\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    ds,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "model = IrisModel()\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    enable_checkpointing=ENABLE_CHECKPOINTING,\n",
    "    logger=LOGGER,\n",
    ")\n",
    "\n",
    "trainer.fit(model, loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f3a4c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\0\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 333.38it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds = IrisDS(train_df)\n",
    "test_ds = IrisDS(\n",
    "    test_df,\n",
    "    has_labels=False,\n",
    "    mean=train_ds.mean,\n",
    "    std=train_ds.std,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "pred_batches = trainer.predict(model, dataloaders=test_loader)\n",
    "\n",
    "logits = torch.cat([b.detach().cpu() for b in pred_batches], dim=0)\n",
    "pred_idx = logits.argmax(dim=1).numpy()\n",
    "\n",
    "classes = [0, 1, 2]\n",
    "pred_labels = [classes[i] for i in pred_idx]\n",
    "\n",
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        \"ID\": range(len(pred_labels)),\n",
    "        \"target\": pred_labels,\n",
    "    }\n",
    ")\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
